# distributed training configurations

num_hops:  1
num_trainers:  1
num_samplers:  2
num_servers:  1

num_server_threads:  1

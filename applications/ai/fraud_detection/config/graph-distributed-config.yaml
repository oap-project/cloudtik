# distributed training configurations

num_hops:  1
num_trainers:  1
num_samplers:  1
num_servers:  1

num_server_threads:  1
num_omp_threads: null

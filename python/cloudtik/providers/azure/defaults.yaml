# Include the common defaults
from: defaults-shared

# Cloud-provider specific configuration.
provider:
    type: azure
    # https://azure.microsoft.com/en-us/global-infrastructure/locations
    location: westus2
    resource_group: cloudtik-resource-group
    # set subscription id otherwise the default from az cli will be used
    # subscription_id: 00000000-0000-0000-0000-000000000000

# How will authenticate with newly launched nodes.
auth:
    ssh_user: ubuntu
    # you must specify paths to matching private and public key pair files
    # use `ssh-keygen -t rsa -b 4096` to generate a new ssh key pair
    ssh_private_key: ~/.ssh/id_rsa
    # changes to this should match what is specified in file_mounts
    ssh_public_key: ~/.ssh/id_rsa.pub

# More specific customization to node configurations can be made using the ARM template azure-vm-template.json file
# See documentation here: https://docs.microsoft.com/en-us/azure/templates/microsoft.compute/2019-03-01/virtualmachines
# Changes to the local file will be used during deployment of the head node, however worker nodes deployment occurs
# on the head node, so changes to the template must be included in the wheel file used in setup_commands section below

# Tell the cluster scaler the allowed node types and the resources they provide.
# The key is the name of the node type, which is just for debugging purposes.
# The node config specifies the launch config and physical instance type.
available_node_types:
    head.default:
        resources: {}
        # Provider-specific config, e.g. instance type.
        node_config:
            azure_arm_parameters:
                vmSize: Standard_D4s_v4
                # List images https://docs.microsoft.com/en-us/azure/virtual-machines/linux/cli-ps-findimage
                imagePublisher: canonical
                imageOffer: 0001-com-ubuntu-server-focal
                imageSku: 20_04-lts-gen2
                imageVersion: latest
                osDiskType: StandardSSD_LRS
                osDiskSizeGB: 100
                dataDisks: []

    worker.default:
        # The minimum number of nodes of this type to launch.
        # This number should be >= 0.
        min_workers: 1
        # The resources provided by this node type.
        resources: {}
        # Provider-specific config, e.g. instance type.
        node_config:
            azure_arm_parameters:
                vmSize: Standard_D4s_v4
                # List images https://docs.microsoft.com/en-us/azure/virtual-machines/linux/cli-ps-findimage
                imagePublisher: canonical
                imageOffer: 0001-com-ubuntu-server-focal
                imageSku: 20_04-lts-gen2
                imageVersion: latest
                osDiskType: StandardSSD_LRS
                osDiskSizeGB: 100
                dataDisks: []
                # comment lines below to not use Spot instances
                priority: Spot
                # set a maximum price for spot instances if desired
                # billingProfile:
                #     maxPrice: -1

# Specify the node type of the head node (as configured above).
head_node_type: head.default

# Files or directories to copy to the head and worker nodes. The format is a
# dictionary from REMOTE_PATH: LOCAL_PATH, e.g.
file_mounts: {
#    "/path1/on/remote/machine": "/path1/on/local/machine",
#    "/path2/on/remote/machine": "/path2/on/local/machine",
     "~/.ssh/id_rsa.pub": "~/.ssh/id_rsa.pub"
}

docker:
    initialization_commands:
        # get rid of annoying Ubuntu message
        - touch ~/.sudo_as_admin_successful
        - which docker || (curl -fsSL https://get.docker.com -o /tmp/get-docker.sh &&
            sudo bash /tmp/get-docker.sh > /dev/null && sudo usermod -aG docker $USER && sudo systemctl restart docker -f)

# List of shell commands to run to set up nodes.
setup_commands:
    - >-
        which conda || (wget -q --show-progress "https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh" -O /tmp/miniconda.sh &&
        /bin/bash /tmp/miniconda.sh -b -u -p ~/anaconda3  &&  ~/anaconda3/bin/conda init  && rm -rf /tmp/miniconda.sh)
    - conda activate cloudtik_py37 || conda create -n cloudtik_py37 -y python=3.7
    - (stat $HOME/anaconda3/envs/cloudtik_py37/ &> /dev/null &&
        echo 'export PATH="$HOME/anaconda3/envs/cloudtik_py37/bin:$PATH"' >> ~/.bashrc) || true

# Custom commands that will be run on the head node after common setup.
head_setup_commands:
    - cloudtik-spark install --head --provider=azure
    - cloudtik-spark configure --head --provider=azure --azure_storage_type=$AZURE_STORAGE_TYPE --azure_storage_account=$AZURE_STORAGE_ACCOUNT --azure_container=$AZURE_CONTAINER --azure_account_key=$AZURE_ACCOUNT_KEY

# Custom commands that will be run on worker nodes after common setup.
worker_setup_commands:
    - cloudtik-spark install --provider=azure
    - cloudtik-spark configure --provider=azure --head_address=$CLOUDTIK_HEAD_IP --azure_storage_type=$AZURE_STORAGE_TYPE --azure_storage_account=$AZURE_STORAGE_ACCOUNT --azure_container=$AZURE_CONTAINER --azure_account_key=$AZURE_ACCOUNT_KEY

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: "prometheus"

    # Override the global default and scrape targets from this job every 10 seconds.
    scrape_interval: 10s

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    # List of Consul service discovery configurations.
    consul_sd_configs:
      # A list of services for which targets are retrieved. If omitted, all services
      # are scraped.
      - services:
          - 'prometheus'
        # The information to access the Consul API. It is to be defined
        # as the Consul documentation requires.
        # [ server: <host> | default = "localhost:8500" ]
        # An optional list of tags used to filter nodes for a given service. Services must contain all tags in the list.
        tags:
          - '{%cluster.name%}'
        # The time after which the provided names are refreshed.
        refresh_interval: 30s
  - job_name: "node-metrics"

    # Override the global default and scrape targets from this job every 10 seconds.
    scrape_interval: 10s

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    # List of DNS service discovery configurations.
    consul_sd_configs:
      # A list of services for which targets are retrieved. If omitted, all services
      # are scraped.
      - services:
          - '{%cluster.name%}-exporter'
        # The information to access the Consul API. It is to be defined
        # as the Consul documentation requires.
        # [ server: <host> | default = "localhost:8500" ]
        # An optional list of tags used to filter nodes for a given service. Services must contain all tags in the list.
        tags:
          - '{%cluster.name%}'
        # The time after which the provided names are refreshed.
        refresh_interval: 30s

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "72c77c30-6d2c-4de9-9293-8e5315c28439",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Distributed Hyperopt and automated MLflow tracking\n",
    "\n",
    "[Hyperopt](https://github.com/hyperopt/hyperopt) is a Python library for hyperparameter tuning. Databricks Runtime for Machine Learning includes an optimized and enhanced version of Hyperopt, including automated MLflow tracking and the `SparkTrials` class for distributed tuning.  \n",
    "\n",
    "This notebook illustrates how to scale up hyperparameter tuning for a single-machine Python ML algorithm and track the results using MLflow. In part 1, you create a single-machine Hyperopt workflow. In part 2, you learn to use the `SparkTrials` class to distribute the workflow calculations across the Spark cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "67f0a665-1d9c-4f4c-81f4-92430dbc68e3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Import required packages and load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ed00c029-b08a-48e2-a7ec-2e3fd035f46f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, SparkTrials, STATUS_OK, Trials\n",
    "\n",
    "# If you are running Databricks Runtime for Machine Learning, `mlflow` is already installed and you can skip the following line. \n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4baa6571-d27d-4b32-b394-efb7904cde56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the iris dataset from scikit-learn\n",
    "iris = iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "34c31380-c073-4dc7-a593-54abc3429e59",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Part 1. Single-machine Hyperopt workflow\n",
    "\n",
    "Here are the steps in a Hyperopt workflow:  \n",
    "1. Define a function to minimize.  \n",
    "2. Define a search space over hyperparameters.  \n",
    "3. Select a search algorithm.  \n",
    "4. Run the tuning algorithm with Hyperopt `fmin()`.\n",
    "\n",
    "For more information, see the [Hyperopt documentation](https://github.com/hyperopt/hyperopt/wiki/FMin)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4e81c560-fb5f-4826-8194-b5c03fba1f2d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def objective(C):\n",
    "    # Create a support vector classifier model\n",
    "    clf = SVC(C=C)\n",
    "    clf.fit(X,y)\n",
    "    \n",
    "    # Use the cross-validation accuracy to compare the models' performance\n",
    "    accuracy = cross_val_score(clf, X, y).mean()\n",
    "    with mlflow.start_run():\n",
    "      mlflow.log_metric(\"C\", C)\n",
    "      mlflow.log_metric(\"loss\", -accuracy)\n",
    "    \n",
    "    # Hyperopt tries to minimize the objective function. A higher accuracy value means a better model, so you must return the negative accuracy.\n",
    "    return {'loss': -accuracy, 'C': C, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d5ab542e-825e-4da8-bf22-ecbbdd32c53e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Define the search space over hyperparameters\n",
    "\n",
    "See the [Hyperopt docs](https://github.com/hyperopt/hyperopt/wiki/FMin#21-parameter-expressions) for details on defining a search space and parameter expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "14dffc27-4ef9-44f3-bcd4-7f81c933946c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "search_space = hp.lognormal('C', 0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5f64acba-0aac-4d7c-aec6-c4a6d662473e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Select a search algorithm\n",
    "\n",
    "The two main choices are:\n",
    "* `hyperopt.tpe.suggest`: Tree of Parzen Estimators, a Bayesian approach which iteratively and adaptively selects new hyperparameter settings to explore based on past results\n",
    "* `hyperopt.rand.suggest`: Random search, a non-adaptive approach that samples over the search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "415a7ec7-e682-48ff-b87e-3bf255a6bd5b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "algo=tpe.suggest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "476f3054-9256-49ae-b9e1-341ade39d047",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Run the tuning algorithm with Hyperopt `fmin()`\n",
    "\n",
    "Set `max_evals` to the maximum number of points in hyperparameter space to test, that is, the maximum number of models to fit and evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f4daef7d-9d45-4c04-8364-9e1e07404f10",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:01<00:00, 13.54trial/s, best loss: -0.9866666666666667]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5001\")\n",
    "\n",
    "mlflow.set_experiment(\"MLflow + HyperOpt + Scikit-Learn\")\n",
    "argmin = fmin(\n",
    "  fn=objective,\n",
    "  space=search_space,\n",
    "  algo=algo,\n",
    "  max_evals=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a046b3be-fc1f-437c-9a8e-4832c2bfcd1d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best value found:  {'C': 5.394497676445904}\n",
      "argmin.get('C'):  5.394497676445904\n"
     ]
    }
   ],
   "source": [
    "# Print the best value found for C\n",
    "print(\"Best value found: \", argmin)\n",
    "print(\"argmin.get('C'): \", argmin.get('C'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7e99ff37-a52d-4cdc-9d3f-2d1bd0da445a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "To view the MLflow experiment associated with the notebook, click the **Experiment** icon in the notebook context bar on the upper right.  There, you can view all runs. To view runs in the MLflow UI, click the icon at the far right next to **Experiment Runs**. \n",
    "\n",
    "To examine the effect of tuning `C`:\n",
    "\n",
    "1. Select the resulting runs and click **Compare**.\n",
    "1. In the Scatter Plot, select **C** for X-axis and **loss** for Y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4e81c560-fb5f-4826-8194-b5c03fba1f2d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def train_and_returnModel(C):\n",
    "    # Create a support vector classifier model\n",
    "    clf = SVC(C=C)\n",
    "    clf.fit(X,y)\n",
    "    \n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'Sklearn-SVC-model-reg' already exists. Creating a new version of this model...\n",
      "2022/07/13 18:57:48 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: Sklearn-SVC-model-reg, version 2\n",
      "Created version '2' of model 'Sklearn-SVC-model-reg'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "model_2_mlflow = trainmodel_2_mlflow = train_and_returnModel(argmin.get('C'))\n",
    "mlflow.sklearn.log_model(model_2_mlflow, \"Sklearn-SVC-model\",registered_model_name=\"Sklearn-SVC-model-reg\")\n",
    "model_uri = \"models:/Sklearn-SVC-model-reg/1\"\n",
    "\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "import pandas as pd\n",
    "loaded_model.predict(pd.DataFrame(X))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "experimentId": "4005336547604444",
    "pythonIndentUnit": 2
   },
   "notebookName": "hyperopt-spark-mlflow",
   "notebookOrigID": 4005336547604444,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa79db9-4289-495b-bbdc-387536c60f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%init_spark\n",
    "launcher.conf.set(\"spark.driver.extraClassPath\", \"/home/cloudtik/runtime/benchmark-tools/spark-sql-perf/target/scala-2.12/spark-sql-perf_2.12-0.5.1-SNAPSHOT.jar:/home/cloudtik/runtime/hadoop/share/hadoop/tools/lib/aws-java-sdk-bundle-1.11.375.jar:/home/cloudtik/runtime/hadoop/share/hadoop/tools/lib/hadoop-aws-3.2.0.jar\")\n",
    "launcher.conf.set(\"spark.executor.extraClassPath\", \"/home/cloudtik/runtime/benchmark-tools/spark-sql-perf/target/scala-2.12/spark-sql-perf_2.12-0.5.1-SNAPSHOT.jar:/home/cloudtik/runtime/hadoop/share/hadoop/tools/lib/aws-java-sdk-bundle-1.11.375.jar:/home/cloudtik/runtime/hadoop/share/hadoop/tools/lib/hadoop-aws-3.2.0.jar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5f326e-2b54-4610-b600-55a348fb0b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "val scaleFactor = \"1\"                   // data scale 1GB\n",
    "val format = \"parquet\"            // support parquer or orc\n",
    "val partitionTables = true        // create partition table\n",
    "// support s3a://s3_bucket, gs://gs_bucket\n",
    "// wasbs://container@storage_account.blob.core.windows.net\n",
    "// abfs://container@storage_account.dfs.core.windows.net\n",
    "val fsdir = \"s3a://s3_bucket_name\" \n",
    "val useDoubleForDecimal = false   // use double format instead of decimal format\n",
    "\n",
    "if (storage == \"hdfs\"){\n",
    "    bucket_name = \"/user/cloudtik/\"   \n",
    "}\n",
    "\n",
    "val user_home = System.getProperty(\"user.home\")\n",
    "val tools_path = s\"${user_home}/runtime/benchmark-tools/tpcds-kit/tools\"\n",
    "val data_path = s\"${fsdir}/shared/data/tpcds/tpcds_${format}/${scaleFactor}\"\n",
    "val database_name = s\"tpcds_${format}_scale_${scaleFactor}_db\"\n",
    "val codec = \"snappy\"\n",
    "val clusterByPartitionColumns = partitionTables\n",
    "\n",
    "val p = scaleFactor.toInt / 2048.0\n",
    "val catalog_returns_p = (263 * p + 1).toInt\n",
    "val catalog_sales_p = (2285 * p * 0.5 * 0.5 + 1).toInt\n",
    "val store_returns_p = (429 * p + 1).toInt\n",
    "val store_sales_p = (3164 * p * 0.5 * 0.5 + 1).toInt\n",
    "val web_returns_p = (198 * p + 1).toInt\n",
    "val web_sales_p = (1207 * p * 0.5 * 0.5 + 1).toInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a90c5c-3ec0-4f59-b8ff-be4f5e944b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import com.databricks.spark.sql.perf.tpcds.TPCDSTables\n",
    "val sc = spark.sqlContext\n",
    "sc.setConf(s\"spark.sql.$format.compression.codec\", codec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c194c365-1cf0-4515-8bd6-3cffbda31250",
   "metadata": {},
   "outputs": [],
   "source": [
    "val tables = new TPCDSTables(spark.sqlContext, tools_path, scaleFactor, useDoubleForDecimal)\n",
    "tables.genData(data_path, format, true, partitionTables, clusterByPartitionColumns, false, \"call_center\", 1)\n",
    "tables.genData(data_path, format, true, partitionTables, clusterByPartitionColumns, false, \"catalog_page\", 1)\n",
    "tables.genData(data_path, format, true, partitionTables, clusterByPartitionColumns, false, \"customer\", 6)\n",
    "tables.genData(data_path, format, true, partitionTables, clusterByPartitionColumns, false, \"customer_address\", 1)\n",
    "tables.genData(data_path, format, true, partitionTables, clusterByPartitionColumns, false, \"customer_demographics\", 1)\n",
    "tables.genData(data_path, format, true, partitionTables, clusterByPartitionColumns, false, \"date_dim\", 1)\n",
    "tables.genData(data_path, format, true, partitionTables, clusterByPartitionColumns, false, \"household_demographics\", 1)\n",
    "tables.genData(data_path, format, true, partitionTables, clusterByPartitionColumns, false, \"income_band\", 1)\n",
    "tables.genData(data_path, format, true, partitionTables, clusterByPartitionColumns, false, \"inventory\", 6)\n",
    "tables.genData(data_path, format, true, partitionTables, clusterByPartitionColumns, false, \"item\", 1)\n",
    "tables.genData(data_path, format, true, partitionTables, clusterByPartitionColumns, false, \"promotion\", 1)\n",
    "tables.genData(data_path, format, true, partitionTables, clusterByPartitionColumns, false, \"reason\", 1)\n",
    "tables.genData(data_path, format, true, partitionTables, clusterByPartitionColumns, false, \"ship_mode\", 1)\n",
    "tables.genData(data_path, format, true, partitionTables, clusterByPartitionColumns, false, \"store\", 1)\n",
    "tables.genData(data_path, format, true, partitionTables, clusterByPartitionColumns, false, \"time_dim\", 1)\n",
    "tables.genData(data_path, format, true, partitionTables, clusterByPartitionColumns, false, \"warehouse\", 1)\n",
    "tables.genData(data_path, format, true, partitionTables, clusterByPartitionColumns, false, \"web_page\", 1)\n",
    "tables.genData(data_path, format, true, partitionTables, clusterByPartitionColumns, false, \"web_site\", 1)\n",
    "tables.genData(data_path, format, true, partitionTables, clusterByPartitionColumns, false, \"catalog_sales\", catalog_sales_p)\n",
    "tables.genData(data_path, format, true, partitionTables, clusterByPartitionColumns, false, \"catalog_returns\", catalog_returns_p)\n",
    "tables.genData(data_path, format, true, partitionTables, clusterByPartitionColumns, false, \"store_sales\", store_sales_p)\n",
    "tables.genData(data_path, format, true, partitionTables, clusterByPartitionColumns, false, \"store_returns\", store_returns_p)\n",
    "tables.genData(data_path, format, true, partitionTables, clusterByPartitionColumns, false, \"web_sales\", web_sales_p)\n",
    "tables.genData(data_path, format, true, partitionTables, clusterByPartitionColumns, false, \"web_returns\", web_returns_p)\n",
    "tables.createExternalTables(data_path, format, database_name, overwrite = true, discoverPartitions = partitionTables)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
